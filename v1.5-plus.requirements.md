# Version 1.5+ Future Possibilities

## Overview

**Status:** NOT PLANNED - User-driven only

**Philosophy:** v1.4 is the **final stable release**. Future versions (v1.5, v1.6, etc.) will **only happen if users actively request specific features**.

**Approach:**
- Evidence-based: "20+ users requested Prometheus metrics"
- Not speculative: Don't build features hoping users want them
- Organic: Let real usage patterns drive evolution
- Minimal: Each release solves one specific, validated need

**This document lists POSSIBLE future features if users demand them. Nothing is committed.**

---

## Potential Future Features (User-Driven)

### IF Users Request: Enhanced Metrics

**Would only build if:** Multiple users report needing detailed signal metrics that basic `Stats()` doesn't provide.

**Possible features:**
- Latency histograms (P50, P95, P99)
- Per-listener metrics
- Error rate tracking
- Prometheus exporter package

**Current status:** v1.4's basic `Stats()` is sufficient unless proven otherwise.

---

### IF Users Request: Testing Utilities

**Would only build if:** Users report difficulty testing signal-based code and can't easily wrap signals themselves.

**Possible features:**
- Mock signals for testing
- Event recorders
- Call spies

**Current status:** Users can create simple wrappers. Build only if pattern emerges.

---

### IF Users Request: Advanced Patterns

**Would only build if:** Same patterns requested by multiple users (composition, filtering, etc.).

**Possible features:**
- Signal composition (Filter, Map, Batch)
- Middleware system
- Listener groups

**Current status:** Users can build these patterns themselves. Only add if strong demand.

---

## Detailed Possibilities (Only If Requested)

### Possibility 1: Enhanced Metrics
**Status:** NOT PLANNED - waiting for user demand

Comprehensive metrics to understand signal behavior in production.

**Requirements:**

#### Core Metrics API
```go
// Enable metrics (disabled by default for zero overhead)
sig.EnableMetrics(true)

// Get current snapshot
stats := sig.Stats()
fmt.Printf("Emits: %d, Errors: %d, Avg Latency: %v\n",
    stats.EmitCount, stats.ErrorCount, stats.AvgLatency)

// Metrics structure
type SignalStats struct {
    // Counts
    EmitCount      uint64
    ListenerCount  int
    ErrorCount     uint64
    PanicCount     uint64

    // Latency (listener execution time)
    MinLatency     time.Duration
    MaxLatency     time.Duration
    AvgLatency     time.Duration
    P50Latency     time.Duration  // Median
    P95Latency     time.Duration
    P99Latency     time.Duration

    // Pool stats (async signals only)
    QueueDepth     int
    ActiveWorkers  int
}
```

#### Per-Listener Metrics (via Metadata)
```go
// Enhanced metadata with metrics
meta := sig.Metadata("listener-key")
fmt.Printf("Calls: %d, Errors: %d, Last Error: %v\n",
    meta.CallCount, meta.ErrorCount, meta.LastError)

type ListenerMetadata struct {
    Key          string
    IsOnce       bool
    AddedAt      time.Time
    CallCount    uint64        // NEW
    ErrorCount   uint64        // NEW
    LastError    error         // NEW
    LastCalled   time.Time     // NEW
    AvgLatency   time.Duration // NEW
}
```

**Success Criteria:**
- <1% CPU overhead when metrics enabled
- Zero overhead when disabled
- Thread-safe concurrent access
- Histogram-based latency tracking (P50, P95, P99)

---

### 2. Prometheus Exporter
**Priority:** HIGH
**Status:** Planned

Separate package for Prometheus integration.

**Requirements:**

```go
// Package: github.com/maniartech/signals/prometheus
import "github.com/maniartech/signals/prometheus"

// Register signal for Prometheus export
prometheus.RegisterSignal(sig, "user_events")

// Exports metrics like:
// signals_emit_total{signal="user_events"} 1234
// signals_error_total{signal="user_events"} 5
// signals_latency_seconds{signal="user_events", quantile="0.5"} 0.001
// signals_latency_seconds{signal="user_events", quantile="0.95"} 0.005
// signals_latency_seconds{signal="user_events", quantile="0.99"} 0.010
```

**Success Criteria:**
- Works with standard Prometheus Go client
- Standard metric naming conventions
- Automatic label generation
- Documented integration examples

---

### 3. Testing Utilities
**Priority:** MEDIUM
**Status:** Planned

Tools to make testing signal-based code easier.

**Requirements:**

#### Mock Signal
```go
// For testing
mock := signals.NewMock[Event](t)

// Use in code under test
processEvents(mock)

// Assertions
mock.AssertEmitted(t, 3)  // Assert 3 emissions
mock.AssertEmittedWith(t, func(e Event) bool {
    return e.Type == "expected"
})
mock.AssertNotEmitted(t)
```

#### Signal Recorder
```go
// Record all emissions for later inspection
recorder := signals.NewRecorder[Event]()
sig.AddListener(recorder.Record, "recorder")

// ... run code ...

// Inspect recorded events
events := recorder.Events()
assert.Len(t, events, 3)
assert.Equal(t, "user-login", events[0].Type)

// Replay in tests
for _, event := range events {
    testSig.Emit(ctx, event)
}
```

#### Signal Spy
```go
// Count calls without side effects
spy := signals.NewSpy[Event]()
sig.AddListener(spy.Listener(), "spy")

// Check later
assert.Equal(t, 5, spy.CallCount())
assert.True(t, spy.WasCalled())
```

**Success Criteria:**
- Works with standard `testing` package
- Compatible with testify assertions
- Minimal, focused API
- Well-documented examples

---

### 4. Production Documentation
**Priority:** LOW
**Status:** Planned

Comprehensive guide for production deployments.

**Topics:**
- Worker pool sizing guide (how to choose)
- Performance tuning patterns
- Error handling best practices
- Monitoring and alerting recommendations
- Common pitfalls and solutions
- Production checklist

---

## Non-Functional Requirements

### Performance

- **Metrics overhead**: <1% CPU when enabled, zero when disabled
- **Memory overhead**: <5MB for metrics storage (histograms, counters)
- **Thread-safe**: All metrics operations concurrent-safe
- **No allocations**: Hot path (Stats() read) should minimize allocations

### Compatibility

- **Backward compatible**: 100% with v1.4
- **Opt-in**: All metrics disabled by default
- **No dependencies**: Core library stays dependency-free
- **Optional packages**: Prometheus exporter is separate module

### Testing

- **Test coverage**: >95% for all new code
- **Race detector**: 100% pass
- **Real-world validation**: Test with actual production patterns
- **Benchmarks**: Measure overhead of metrics collection

---

## Out of Scope for v1.5

### Explicitly Not Included

- ❌ **Auto-scaling worker pools** - Complex, not production-validated need
- ❌ **Time-series storage** - Use Prometheus/Grafana
- ❌ **Built-in profiling** - Use Go's pprof
- ❌ **Distributed tracing** - Use OpenTelemetry if needed
- ❌ **Advanced aggregation** - Keep it simple
- ❌ **Real-time dashboards** - Use Grafana

### Rationale

v1.5 provides the **data** (metrics, testing tools), but relies on external tools for **analysis** (Prometheus, Grafana, standard testing frameworks). This keeps the library focused and maintainable.

---

## How Future Versions Would Work (IF They Happen)

**IF** users request features and a future version is released, it would maintain backward compatibility:

```go
// v1.4 code continues to work forever
sig := signals.New[Event]()
sig.AddListener(listener, "key")
sig.Emit(ctx, event)

// IF enhanced metrics are added (only if users request):
stats := sig.DetailedStats()  // Hypothetical

// IF testing utilities are added (only if users request):
mock := signals.NewMock[Event](t)  // Hypothetical
```

**But again:** These only happen if multiple users demonstrate real need.

---

## Decision Criteria for Future Releases

**Before building ANY future version, require:**

1. **User demand**: 10+ users request the same feature via issues/discussions
2. **Can't DIY**: Users can't easily solve it themselves
3. **In scope**: Feature fits in-process signaling (no enterprise theater)
4. **Maintainable**: Won't create maintenance burden
5. **Evidence**: Real production use cases, not speculation

**Examples of what WOULD trigger a release:**
- "15 users asked for Prometheus metrics" → Consider metrics package
- "Multiple bug reports about testing difficulties" → Consider test utilities
- "Common pattern in 20+ codebases" → Consider adding pattern to library

**Examples of what would NOT trigger a release:**
- "Might be useful someday" → No
- "Enterprise feature checklist" → No
- "Competing library has it" → Not enough reason
- "Only 2 users mentioned it" → Too few

---

## Timeline

**v1.4 = Final:** Complete, stable, production-ready.

**v1.5+ = TBD:** Only if users demand it. No timeline, no roadmap, no promises.

---

*Version 1.4 is designed to be the final release. Future versions exist only if users prove they need them.*